{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transfrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform is a function that gets a signal in the time domain as input, and outputs its decomposition into frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mel spectrogram is a visual representation of audio frequencies over time, specifically designed to match how humans perceive sound. Here's what you're seeing:\n",
    "\n",
    "The x-axis represents time (left to right)\n",
    "\n",
    "The y-axis represents frequency (bottom to top), but in \"mel\" scale which is more similar to how humans perceive pitch\n",
    "\n",
    "The brightness/intensity of each point represents the energy/power at that specific frequency and time\n",
    "\n",
    "In our visualization, we're using a grayscale where:\n",
    "\n",
    "\n",
    "Brighter areas (closer to white) = stronger frequencies\n",
    "\n",
    "Darker areas (closer to black) = weaker frequencies\n",
    "\n",
    "For piano music, you should see:\n",
    "\n",
    "Vertical lines when notes are played (sudden changes in frequency)\n",
    "\n",
    "Horizontal bands corresponding to different notes\n",
    "\n",
    "Brighter areas where notes are being played"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"notes\": [\n",
    "    {\n",
    "      \"note\": 60,        # MIDI note number (60 = middle C)\n",
    "      \"start_time\": 0.0, # When the note starts (in seconds)\n",
    "      \"end_time\": 0.5,   # When the note ends (in seconds)\n",
    "      \"velocity\": 100    # How hard the note was played (0-127)\n",
    "    },\n",
    "    # ... more notes\n",
    "  ],\n",
    "  \"mel_spectrogram\": [...], # The same data used for visualization\n",
    "  \"duration\": 1.5          # Total duration of the audio in seconds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel spectrogram array values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dimension (rows): Represents different frequency bands in \"mel\" scale\n",
    "\n",
    "There are 128 frequency bands in the mel scale\n",
    "\n",
    "Lower rows = lower frequencies (bass notes)\n",
    "\n",
    "Higher rows = higher frequencies (treble notes)\n",
    "\n",
    "Second dimension (columns): Represents time\n",
    "\n",
    "Each column is a time slice\n",
    "\n",
    "The number of columns depends on the audio duration and the hop length (time between each slice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
